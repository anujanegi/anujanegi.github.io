<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" hreflang="en" /><updated>2024-07-12T12:08:32+02:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">blank</title><subtitle>Anuja&apos;s personal website.
</subtitle><entry><title type="html">Is brain Imaging for pain measurement reliable enough for the courtroom?</title><link href="http://localhost:4000/blog/2021/Is-brain-Imaging-for-pain-measurement-reliable-enough-for-the-courtroom/" rel="alternate" type="text/html" title="Is brain Imaging for pain measurement reliable enough for the courtroom?" /><published>2021-03-30T00:00:00+02:00</published><updated>2021-03-30T00:00:00+02:00</updated><id>http://localhost:4000/blog/2021/Is%20brain%20Imaging%20for%20pain%20measurement%20reliable%20enough%20for%20the%20courtroom</id><content type="html" xml:base="http://localhost:4000/blog/2021/Is-brain-Imaging-for-pain-measurement-reliable-enough-for-the-courtroom/"><![CDATA[<p><a href="https://www.nature.com/news/neuroscience-in-court-the-painful-truth-1.16985">Link to Paper</a></p>

<p>In recent years, several neuroimaging-based companies claim to detect pain signals using fMRI (functional magnetic resonance imaging). Such scans for measuring pain have been used as evidence in court trials in cases involving claims of unresolved pain. Although there is a real chance at helping someone in pain by providing “proof of pain” through brain imaging techniques, it is also important to examine if such methods are actually even correct and ethical or if they can be fooled, an allure to wrongly acquiring money.</p>

<p>Pain is a very subjective experience. To objectively quantify it, we look at the source of the experience - the brain. Several researchers over the years have tried to understand the nature of pain using fMRI on the ground that pain shares common elements. A study at the University of Colorado investigated pain’s signature by placing people in an fMRI scanner as they touch a hot plate. Note that acute pain is being measured here. However, most court cases question the truthfulness of chronic pain. A study at the Northwestern University in Chicago scanned people with back injuries over the course of one or more years. A shift of the pain signature from the insula (associated with acute pain) to the amygdala (associated with emotion) and medial prefrontal cortex (associated with cognitive behavior) was observed; “pain is becoming more internalized”. This suggests an emotional connection to chronic pain, which may also reinforce each other.</p>

<p>It is relevant for science to research the nature of pain and attempt to quantify it objectively. But are the current methods accurate enough to be used in court? Given how fMRI scans have been regarded as evidence for pain in court, it is critical to scrutinize the feasibility of pain imaging both from a technical and ethical point of view and discuss its limitations.</p>

<p><strong>Technical Feasibility</strong></p>

<p>Given the current state of the art, it is fair to say that the current advancement in pain measurement by brain imaging is not reliable. Maybe it will be sometime in the future, but not now. Pain cannot be reliably localized to a particular brain region. Hence finding biomarkers might be advantageous. Even if the exact biomarkers are known, the challenge exists in quantifying the degree of pain at a personal level and associating it with brain regions and brain activity.</p>

<p>Something as subjective as pain is difficult to detect using fMRI. Increased brain activity might suggest more pain, but does not necessarily quantify pain well enough to take a legal decision. Someone’s pain tolerance might be someone else’s nightmare. The subjective character of pain makes interpersonal comparisons hard. It is important to not undervalue someone’s pain and make a decision based on it by objectively measuring pain from different subjects on a common scale. Further, all this study is based on inverse inference, which might not even be true given the abstract nature of pain. Signatures detected in pain could be seen in subjects, not in pain.</p>

<p>fMRI mainly measures blood flow and has a poor temporal resolution which is an issue in measuring acute pain. EEG can be useful to detect such changes. During studies, for eg. using the hot plate, it can be difficult to decouple actual pain from the thought of pain.  EEG and MEG with higher temporal resolution could help deal with this by separating the pain response from anticipation. But this is more useful for acute pain. Once we know the biomarkers, using multimodal imaging methods could be more comprehensive, if the biomarker shows up in all methods. For chronic pain, I think the focus should be placed on detecting maladaptive changes and functional reorganization in the brain images as an indication of pain.</p>

<p>It is crucial to think about how one might fool the imaging by thinking of pain. People could also physically/mentally hurt themselves before a scan to get a positive result. Therefore, a better understanding of pain signatures and their causes is of need. However, the potential for easily deceiving the method should not prevent us from studying this further.</p>

<p><strong>Ethical Analysis</strong></p>

<p>Let us assume that we have a perfect way of detecting and quantifying pain using fMRI. Even then it is questionable to measure how much pain a person is in, let alone use it is as evidence in court. Can courts even accept such brain imaging results as proof of pain? If yes, how much weightage should be given to such evidence, given how there is a clear “neuro” bias found in public.</p>

<p>To “measure” chronic pain, a woman with back pain was imaged before and after walking. This makes us question if it is even okay to force people in chronic pain to perform tasks to induce more pain, such that a biomarker is more strongly measurable? Further, tests like an fMRI scan are not accessible and also really expensive and can even cost up to $4500. The cost can also hinder people who may genuinely need such a piece of evidence in court from having one.</p>

<p>Accepting such brain images in court will also increase the burden of proving one’s pain. It can also lead to forcing people to undertake these tests becoming commonplace for use in health insurance claims, medicine prescription, etc. It can cause trust issues and make us question people when they say they are in pain if they don’t have a positive pain test.</p>

<p>The incentive structure of this method can encourage people to cheat for money, leaves, insurance claims. It can also force people who actually are in pain, to wait to take such a test when they are hurting more. Additionally, making interpersonal comparisons of pain just for treatment, compensation, etc is unjust and gives the idea that being more in pain is advantageous.</p>

<p>Having proper pain measurement methods does not make the underlying social issue that makes such a test relevant in court in the first place. The incentive for most of these cases in court is poor health insurance systems. A well-functioning health care system may reduce the need for pain detection, at least in legal cases.</p>

<p>All this said pain research is important both for science and society. Such a method can help to secure an out-of-court settlement, saving a lot of time and money. It will also help combat stigma against people in chronic pain by providing a way of it. The communication of scientific breakthroughs influences the way the public perceives and utilizes such technologies as pain measurement. Therefore it is important to both introduce and use such pain measurement techniques judiciously.</p>]]></content><author><name></name></author><category term="papers-i-read" /><category term="neuroscience" /><category term="ethics" /><summary type="html"><![CDATA[Link to Paper]]></summary></entry><entry><title type="html">Slow Dynamics and High Variability in Balanced Cortical Networks with Clustered Connection</title><link href="http://localhost:4000/blog/2021/Slow-Dynamics-and-High-Variability-in-Balanced-Cortical-Networks-with-Clustered-Connection/" rel="alternate" type="text/html" title="Slow Dynamics and High Variability in Balanced Cortical Networks with Clustered Connection" /><published>2021-02-10T00:00:00+01:00</published><updated>2021-02-10T00:00:00+01:00</updated><id>http://localhost:4000/blog/2021/Slow%20Dynamics%20and%20High%20Variability%20in%20Balanced%20Cortical%20Networks%20with%20Clustered%20Connection</id><content type="html" xml:base="http://localhost:4000/blog/2021/Slow-Dynamics-and-High-Variability-in-Balanced-Cortical-Networks-with-Clustered-Connection/"><![CDATA[<p><a href="https://www.nature.com/articles/nn.3220">Link to Paper</a></p>

<p>Action potential is the principal mode of neural communication. It’s a way to represent and process information through the temporal and spatial pattern of spikes. These spiking patterns are very variable, even across similar trials. Normally, these variabilities are treated as arising from stochastic (Poisson) generation of spikes on the basis of a firing rate. In network simulations, it is a common practise to assume random homogeneous connectivity between neurons i.e. a uniform network. However, anatomical studies indicate that is not a good approximation. To combat this, models are often designed to allow firing rates to themselves be variable across trials. Thus, the observed data is often ‘doubly stochastic’: a variable firing rate gives rise to variable spiking. Although this allows for a good description of the data,  there is no known biophysics of neurons to account for this.</p>

<p>This paper shows how a simulated network of spiking neurons can exhibit both spontaneous firing rate fluctuations and spontaneous spiking variability as a network property with deterministic neurons, without endowing a firing rate directly. To do this, the principle of balanced excitation and inhibition is employed. To induce firing rate fluctuations, clustered connections are introduced in a balanced network of spiking neurons - the connection probability for two neurons in the same cluster is higher than for two neurons belonging to different clusters. These clusters cause  a group of spiking neurons to act like a firing rate unit, yielding the desired behaviour in firing-rate fluctuations. It is interesting to note that these fluctuations can emerge when less than 4% of the connections of a network are rearranged to form clusters. Such a small modification is sufficient to increase the cluster excitation by five times!</p>

<p>The paper further investigates the effects of introducing clustered excitatory connections in balanced networks. A small network of uniform networks is stimulated. Clustering is then introduced in this network. To study how specific clusters increase/decrease their firing rates over long time periods, several statistical analysis methods are employed.
Network models were simulated for 4000 excitatory neurons and 1000 inhibitory LIF neurons, without noise. For the clustered network, 50 clusters of 80 neurons each were introduced in the uniform network with a connection probability outside the cluster to be 2.5. The voltage trace and spike raster plot of excitatory neurons for uniform and clustered network show the irregular firing of the neurons. Neurons asynchronously fire as expected.  As clustering is introduced, neurons in the same cluster act as a firing unit. Neurons now have synchronous irregular firing. Entire clusters either fire together or don’t fire at all. This bi-stability introduces slow dynamics during which clusters transiently increase/decrease their firing rate along with randomness in the spike times of individual neurons, yielding dynamics substantially different from those of the uniform network despite the small change in architecture.</p>

<p>Fluctuations in firing rate exist due to the competition between clusters. Each cluster tries to excite itself and get in the upstate while inhibiting the others. When one cluster becomes active, it tends to stay active while continually suppressing the others. Hence, the active cluster has an elevated overall firing rate. Later, a different cluster may win the competition and become active. This ongoing competition between the clusters produces extended fluctuations in firing rate.</p>

<p>In conclusion we can now reproduce experimental data in simulations without the need of external factors but instead just from the behaviour of the clustered networks itself. It successfully shows that a small alteration of the connectivity in a uniform network leads to the introduction of dynamical phenomena, namely the slow firing rate fluctuations in spontaneous conditions while spike time variability remains intact.</p>]]></content><author><name></name></author><category term="papers-i-read" /><category term="neuroscience" /><summary type="html"><![CDATA[Link to Paper]]></summary></entry><entry><title type="html">An Integrated Brain-machine Interface platform with thousands of channels</title><link href="http://localhost:4000/blog/2020/An-Integrated-Brain-machine-Interface-platform-with-thousands-of-channel/" rel="alternate" type="text/html" title="An Integrated Brain-machine Interface platform with thousands of channels" /><published>2020-11-11T00:00:00+01:00</published><updated>2020-11-11T00:00:00+01:00</updated><id>http://localhost:4000/blog/2020/An%20Integrated%20Brain-machine%20Interface%20platform%20with%20thousands%20of%20channel</id><content type="html" xml:base="http://localhost:4000/blog/2020/An-Integrated-Brain-machine-Interface-platform-with-thousands-of-channel/"><![CDATA[<p><a href="https://www.biorxiv.org/content/10.1101/703801v4">Link to Paper</a></p>

<p>The paper reports on Neuralink’s approach to scalable and extensible brain machine interfaces. They successfully develop flexible polymer probes and a robot to insert them, achieving a BMI with a high channel count and great single-spike resolution.</p>

<p>Existing electrodes are incapable of long term neural recording as they are either metal or semiconductor based. To combat this, a thin and flexible electrode made primarily from polyimide encapsulating a gold film is developed. It is both better in terms of longevity and biocompatibility. These ultra-fine polymer probes are patterned on a wafer, with 3,072 electrodes per array distributed across 96 threads. Each thread has 32 independent probes. Different treatments for surface modification are used to lower the impedance of these probes.</p>

<p>For precise and automated insertion of these probes, a neurosurgical robot is built. The robot consists of a needle (for holding threads and penetrating brain tissue) and an imaging stack (for live viewing, guiding, insertion and verification of threads). A custom software is used to pre select insertion sites and define robot insertion paths. The robot is capable of inserting 192 electrodes per minute, each one at a time! The flexibility to insert these flexible probes at target specific regions, without any vasculature at such speed, is commendable.</p>

<p>The arrays of electrodes are packaged into tiny implantable devices capable of recording from 3072 channels simultaneously. A custom application specific integrated circuit (ASIC) is used for
on-board amplification and digitization of signals. The system was tested on freely moving rats.</p>

<p>I believe that BMIs hold the potential for treatment of several neurological disorders. Due to the restrain on reading from a large number of neurons, their clinical use has been limited. The system presented in the paper, is a significant step towards fully implantable human BMI systems.</p>]]></content><author><name></name></author><category term="papers-i-read" /><category term="bci" /><category term="neuroscience" /><summary type="html"><![CDATA[Link to Paper]]></summary></entry><entry><title type="html">Human level Control through Deep Reinforcement Learning</title><link href="http://localhost:4000/blog/2020/Human-level-Control-through-Deep-Reinforcement-Learning/" rel="alternate" type="text/html" title="Human level Control through Deep Reinforcement Learning" /><published>2020-10-15T00:00:00+02:00</published><updated>2020-10-15T00:00:00+02:00</updated><id>http://localhost:4000/blog/2020/Human-level%20Control%20through%20Deep%20Reinforcement%20Learning</id><content type="html" xml:base="http://localhost:4000/blog/2020/Human-level-Control-through-Deep-Reinforcement-Learning/"><![CDATA[<p><a href="https://www.nature.com/articles/nature14236?wm=book_wap_0005">Link to Paper</a></p>

<p>Reinforcement learning is being used to master several difficult tasks. However, these agents struggle in deriving representations from high-dimensional sensory inputs. On the other hand, humans ace at these tasks through a “harmonious combination of reinforcement learning and hierarchical sensory processing system”.</p>

<p>This work spans the disjoint between high dimensional inputs and actions by combining machine learning with biologically inspired techniques to create RL agents capable of mastering diverse complex tasks. A novel deep Q-network agent incorporating reinforcement learning with ANN, and replay algorithm is built.</p>

<p>The deep convolutional NN is used to approximate the action-value(Q) function. Due to this nonlinear function, the RL algorithm can diverge. To stabilize this, the observations are randomized to remove correlations (though experience replay) and correlation in the trager are removed by iteratively updating Q periodically. Hence, the target’s Q-learning updates are generated separately by the network.</p>

<p>The Q-network agent draws insight from experience replay, based on the neurobiological understanding that perceptual learning in the primate visual cortex is influenced by reward signals. Hence the agents experiences are stored at each time step.</p>

<p>Receiving only the pixels and game score as inputs, the agent outperforms human experts, while surpassing all current benchmarks on 49 Atari 2600 games. To be able to use the same learning rate across multiple games, the reward structure is modified to limit the error derivative. All positive, negative and zero rewards were clipped at 1, 21 and left unchanged respectively.</p>

<p>It is interesting to note that this is achieved by using the same algorithm, network architecture and hyperparameters across all games. The agent is able to learn representations and generalise it to varied other environments and control policies, than on which it was trained.It is hence capable of learning an array of complex tasks with the same parameter set and system.</p>]]></content><author><name></name></author><category term="papers-i-read" /><category term="reinforcement-learning" /><summary type="html"><![CDATA[Link to Paper]]></summary></entry><entry><title type="html">Assessing Game Balance with AlphaZero- Exploring Alternative Rule Sets in Chess</title><link href="http://localhost:4000/blog/2020/Assessing-Game-Balance-with-AlphaZero-Exploring-Alternative-Rule-Sets-in-Chess/" rel="alternate" type="text/html" title="Assessing Game Balance with AlphaZero- Exploring Alternative Rule Sets in Chess" /><published>2020-09-28T00:00:00+02:00</published><updated>2020-09-28T00:00:00+02:00</updated><id>http://localhost:4000/blog/2020/Assessing%20Game%20Balance%20with%20AlphaZero:%20Exploring%20Alternative%20Rule%20Sets%20in%20Chess</id><content type="html" xml:base="http://localhost:4000/blog/2020/Assessing-Game-Balance-with-AlphaZero-Exploring-Alternative-Rule-Sets-in-Chess/"><![CDATA[<p><a href="https://arxiv.org/pdf/2009.04374.pdf">Link to Paper</a></p>

<blockquote>
  <p>Turing (1953) asked, “Could one make a machine to play chess,
and to improve its play, game by game, profiting from its
experience?”</p>
</blockquote>

<p>This chess paper reminds how beautiful a game can be. The paper covers too much for me to be able to wrap in this article. Regardless.</p>

<p>The paper utilises AlphaZero for game balance assessment of new chess variants. By learning each variant, the potential of these chess adaptations is determined. The paper answers how fair a variant of chess is? What happens when even a small rule is changed?</p>

<p>Nine alterations to the modern ches are explored in the paper, including wild variants like self-capture and pawn sideways. As no prior gaming knowledge is required for AlphaZero to train, different rules are rapidly explored through both quantitative(expected scores, draw rates, effects of special moves, etc) and qualitative comparisons.</p>

<p>Few points from the paper -</p>
<ul>
  <li>Alpha Zero was surprisingly accurate in computing material value of pieces proportionate to pawn. It computes 1-3.05-3.33-5.63-9.5! In classical chess it is 1-3-3.5-5-9!</li>
  <li>To encourage exploration by AlphaZero during training, a small amount of noise is injected along with the prior move probabilities.</li>
  <li>To learn the chess piece values, a linear model is trained over sampled states of games with a mean-square-error loss and tanh activation. Simple and straight formulation!</li>
  <li>Several chess variants- Torpedo, Semi-torpedo, No-castling chess and Stalemate, turn out to be more decisive than classical chess.</li>
  <li>In the self-capture games, AlphaZero captures its own queen when in an already winning position!</li>
</ul>

<p>The paper is a very interesting read! Chess is theoretically a drawn dame, testing alternate hypotheses and actually simulating decades of human play with them within a few hours, something that would have taken a long period of time and a large number of human players, is super neat!</p>

<p>Maybe this can be the new standard to design new games in the future!</p>]]></content><author><name></name></author><category term="papers-i-read" /><category term="deep-learning" /><category term="AlphaZero" /><summary type="html"><![CDATA[Link to Paper]]></summary></entry><entry><title type="html">Unsupervised Translation of Programming Languages</title><link href="http://localhost:4000/blog/2020/Unsupervised-Translation-of-Programming-Languages/" rel="alternate" type="text/html" title="Unsupervised Translation of Programming Languages" /><published>2020-09-11T00:00:00+02:00</published><updated>2020-09-11T00:00:00+02:00</updated><id>http://localhost:4000/blog/2020/Unsupervised%20Translation%20of%20Programming%20Languages</id><content type="html" xml:base="http://localhost:4000/blog/2020/Unsupervised-Translation-of-Programming-Languages/"><![CDATA[<p><a href="https://arxiv.org/abs/2006.03511">Link to Paper</a></p>

<p>The paper introduces a novel unsupervised neural transcompiler, by purely using monolingual open source code from public Github repositories. The transcompiler is capable of converting code between C++, Java and Python programs, outperforming existing benchmarks.</p>

<p>Majority of existing transcompilers are rule-based and have several disadvantages - tedious to write handcrafted rules, requires expertise in both source and target programming languages and issues with inferring variables from a dynamically to statically typed language. Other supervised approaches fall short due to the limited availability of parallel data. Hence, being able to do unsupervised machine translation discards all this.</p>

<p>To achieve the transcompiler, a single transcoder model is trained for all programming languages using a seq2seq model with attention, and an encoder-decoder(transformer) architecture. The three principles of machine translation are used -</p>

<p><strong>Initialisaztion</strong>. The model is initialised with cross-lingual words (anchor points - for, while, if) to map the same instructions to the same representation. For creating these representations, random words of an input code are masked and then predicted, at each iteration by the cross-lingual language(XLM) model.</p>

<p><strong>Language modelling</strong>. The encoder and the decoder are initialised with the pretrained XLM model. The decoder is trained with a denoising auto-encoding(DAE) objective so that it always generates valid sequences even with noisy input, making the encoder more robust. The first token of the input specifies the programming language. Hence, one can decode in python and encode in java.</p>

<p><strong>Back translation</strong>. Deriving from supervised machine translation, this is effectively used to improve model performance. It basically allows the model to itself generate data to train on by using a target-to-source technique.</p>

<p>The transcoder model is evaluated with 852 parallel functions and unit tests for each. For validation and test sets, parallel functions from GeeksforGeeks were taken. It is noteworthy that a new metric, “computational accuracy”(evaluates if the same output is given on the same inputs) was used to score the model rather than the lacking BLEU and reference match scoring.</p>]]></content><author><name></name></author><category term="papers-i-read" /><category term="unsupervised-learning" /><summary type="html"><![CDATA[Link to Paper]]></summary></entry><entry><title type="html">Neuroscience Inspired Artificial Intelligence</title><link href="http://localhost:4000/blog/2020/Neuroscience-Inspired-Artificial-Intelligence/" rel="alternate" type="text/html" title="Neuroscience Inspired Artificial Intelligence" /><published>2020-09-03T00:00:00+02:00</published><updated>2020-09-03T00:00:00+02:00</updated><id>http://localhost:4000/blog/2020/Neuroscience%20Inspired%20Artificial%20Intelligence</id><content type="html" xml:base="http://localhost:4000/blog/2020/Neuroscience-Inspired-Artificial-Intelligence/"><![CDATA[<p><a href="https://deepmind.com/research/publications/neuroscience-inspired-artificial-intelligence">Link to Paper</a></p>

<p>The fields of neuroscience and artificial intelligence are unquestionably intertwined. To bridge the declining communication between the fields, the authors survey past interactions in the fields and talk about the current advances in AI that are inspired by neuroscience. The paper concludes by how future research can advantage from drawing insights from both disciplines and also explores how neuroscience can be benefited from AI.</p>

<p>The paper begins with the premise that to build Turing intelligent systems, one must scrutinize and learn from the human mind - the only existing proof of such an intelligent system. Neuroscience can hence not only provide inspiration for the development of these intelligent systems but also be a validation tool for AI techniques if it is subsequently found in the human brain.</p>

<p>From historic interactions, it is evident that the origins of AI lie in neuroscience. It was only to study neural computations that ANNs were constructed. This served as the foundation to deep learning. The backpropagation algorithm originated from the parallel distributed processing(PDP) movement proposed in human cognition, dropout was inspired by stochasticity in neurons, and reinforcement learning originated from animal learning.</p>

<p>From recent advancements, though the attention mechanism was developed unconsciously of its existence in neuroscience, neurocomputational models used a piecemeal approach (isolate and prioritize information that is relevant at the moment) back in 1993. This only emphasizes how collaboration between the two domains is of significance. Parallels are also drawn between episodic memories (in the medial temporal lobe of the hippocampus) and the “experience replay” in the deep-Q-network. A DQN can hence even be thought of as a primitive hippocampus. Similarly, insights from the working memory in humans can be seen in RNN and LSTM architectures. Intelligent systems are now aiming to be able to learn from different tasks over distributed timescales. This is consistent with studies that “memories can be protected from interference through synapses that transition between a cascade of states with different levels of plasticity”.</p>

<p>The authors then discuss how in the future AI systems can utilize studies from neurocomputation to bridge the gap between machine and human intelligence. Human cognition can aid to develop networks that can “learn to learn”, and be capable of efficient and transfer learning. The authors truly believe that by transferring insights from brain mechanisms, one can facilitate building agents capable of planning hierarchically, generalization, and be truly creative. Also, techniques from neuroimaging and equivalents of single-cell recordings can be employed to make black-box AI interpretable and maybe even explainable.</p>

<p>The paper is concluded by appreciating AI techniques for analyzing neuroimaging datasets and promotes forming a “virtuous cycle” to advance both fields.</p>]]></content><author><name></name></author><category term="papers-i-read" /><category term="neuroscience" /><category term="artificial-intelligence" /><summary type="html"><![CDATA[Link to Paper]]></summary></entry><entry><title type="html">Natural Image Reconstruction from Brain Waves - a Novel Visual BCI System with Native Feedback</title><link href="http://localhost:4000/blog/2020/Natural-Image-Reconstruction-from-Brain-Waves-a-Novel-Visual-BCI-System-with-Native-Feedback/" rel="alternate" type="text/html" title="Natural Image Reconstruction from Brain Waves - a Novel Visual BCI System with Native Feedback" /><published>2020-08-26T00:00:00+02:00</published><updated>2020-08-26T00:00:00+02:00</updated><id>http://localhost:4000/blog/2020/Natural%20Image%20Reconstruction%20from%20Brain%20Waves:%20a%20Novel%20Visual%20BCI%20System%20with%20Native%20Feedback</id><content type="html" xml:base="http://localhost:4000/blog/2020/Natural-Image-Reconstruction-from-Brain-Waves-a-Novel-Visual-BCI-System-with-Native-Feedback/"><![CDATA[<p><a href="https://www.biorxiv.org/content/10.1101/787101v3">Link to Paper</a></p>

<p>Utilizing non-invasive EEG recordings, the paper introduces a closed BCI system capable of reconstructing observed or imagined stimuli images from co-occurring brain parameters. The authors are successfully able to gather from the advantages of both synchronous and asynchronous BCI systems. They use the correlation between long-term evoked responses and mental states triggered by a particular simulation, along with native feedback, to develop this novel BCI paradigm.</p>

<p>The two main objectives of the research are to study the brain activity upon continuous visual stimuli and to then develop a model capable of mapping these EEG features to the stimuli and hence reconstruct the natural image back.</p>

<p>To explore the first, the EEG signals of 17 healthy human subjects observing video clips of varied objects (from different categories) were recorded over two sessions. To avoid parasite ERPs, no clips were repeated and no montage transitions were included.</p>

<p>To achieve the second objective, feature extraction was performed within the ICA matrix space, using artifact rejection, Fourier transforms for spectral feature extraction, and PCA for reduced dimensionality. These features were classified using LDA (linear discriminant analysis into categories. To guarantee that signals aren’t biased to any class, the “Goldberg mechanism” category is chucked on the caution of containing parasite discriminative features due to eye movement. How cautious!</p>

<p>To establish the native neurofeedback, an image autoencoder (independent of any neurophysiological data) is used for the reconstruction of natural images. I like how the loss function uses distance, angle, and pixel loss for parameter tuning. Further, availing the fact that the experiment has continuous data, RNNs are used for the EEG feature mapping (translates EEF feature domain to image decoder space).</p>

<p>While testing, a subject was also able to switch between the categories at his own will without even watching the actual video clips and was hence able to master imaginary switching within 10 minutes of training! The results obtained are impressive and make me even more excited about what is possible using BCI systems in the future. Taking inspiration from this, how can we head towards better brain-controlled technology?</p>

<p>The authors successfully show their hypothesis, “observing the visual stimuli of different categories trigger distinct brain states’’ and that it is possible to vary the stimuli without affecting the inter-category separability. They achieve a closed-loop BCI system capable of real-time, mind-driven image reconstruction using EEG features. As there are no additional cognitive tasks associated, it makes it even suitable for those patients with cognitive disorders.</p>

<p>Food for the brain -  If we have these models trained on bigger datasets and, if someone who is trained and effectively able to master imaginary and precisely visualize images in their own mind - could we then visualize thoughts?</p>]]></content><author><name></name></author><category term="papers-i-read" /><category term="image-reconstruction" /><category term="bci" /><category term="eeg" /><summary type="html"><![CDATA[Link to Paper]]></summary></entry><entry><title type="html">Computing Machinery and Intelligence</title><link href="http://localhost:4000/blog/2020/Computing-Machinery-and-Intelligence/" rel="alternate" type="text/html" title="Computing Machinery and Intelligence" /><published>2020-08-13T00:00:00+02:00</published><updated>2020-08-13T00:00:00+02:00</updated><id>http://localhost:4000/blog/2020/Computing%20Machinery%20and%20Intelligence</id><content type="html" xml:base="http://localhost:4000/blog/2020/Computing-Machinery-and-Intelligence/"><![CDATA[<p><a href="https://academic.oup.com/mind/article/LIX/236/433/986238">Link to Paper</a></p>

<p>This paper laid foundations of the highly influential Turing test by exploring the question “Can machines think?”.  To answer this question unambiguously, it is replaced by yet another question, “Are there imaginable digital computers which would do well in the imitation game”?</p>

<p>The proposed imitation game has 3 subjects - A and B being a machine and a human, and C being the interrogator who is tasked to make the correct identification. This has to be done without sight, touch, voice, or any demands of practical demonstration. It is argued that this test shouldn’t be critiqued as the odds are heavily against the machine.</p>

<p>The paper discusses the meaning of the words ‘machine’ and ‘think’, followed by the remainder of the paper refuting and arguing against plausible objections that can be made to both the question and the proposition. These objections vary widely from theological to mathematical views. Few riveting defenses from the various contrary views dealt with -</p>

<ul>
  <li>
    <p>The argument from consciousness is tackled by explaining how to be sure if a machine thinks is to be the machine and feel oneself thinking in it. Hence, what a man feels/thinks cannot be justified by any notice and similar is the case of a machine.
Lady Lovelace’s objection implying that a machine can never do anything really new is argued by saying that there is no original work, but simply understanding what it is by virtue of growth through teaching.</p>
  </li>
  <li>
    <p>It is interesting how a digital computer is explained to be a ‘human computer’. In the extrasensory perception argument, the clause of using telepathy-proof rooms are added, if it is ever to be possible!</p>
  </li>
  <li>
    <p>The skin of the onion analogy describes how the whole human mind might just be mechanical, where the “real” mind does not exist and might merely be just another skin/layer.</p>
  </li>
</ul>

<p>It’s nice to see how the idea of discrete-state machines is connected to both neurology and Laplace’s view of the universe as a whole. In trying to build a thinking machine and taking ideas from a human mind to do so, it is also explored how this can be done using the initial state of a child, and applying education and experiences to make it an adult one. Hence, instead of trying to stimulate an adult’s mind, why not replace it with a child’s? Other parameters of evolution like heredity and mutation are also considered.</p>

<p>I appreciate how the paper was so ahead of its time. It makes me appreciate the brilliant people that laid the foundations of computing and intelligence even more. It is also noteworthy that importance is given to the fact that the main question is set to be asked for an imaginable computer that would do well in the test in the future, both while designing the test and during the discussion.</p>

<p>This paper is a very different read than the usual academic papers. Through the paper, it can also be seen how socially aware Alan Turing was as a human. The paper shows his views on sexuality, religion, god, and human supremacy.  Few quotes from the paper that made me smirk/applaud  -</p>

<ul>
  <li>
    <p>“The game may perhaps be criticized on the ground that the odds are weighted too heavily against the machine. If the man were to try and pretend to be the machine he would clearly make a very poor showing. He would be given away at once by slowness and inaccuracy in arithmetic. “</p>
  </li>
  <li>
    <p>The “Heads in the Sand” objection - “The consequences of machines thinking would be too dreadful. Let us hope and believe that they cannot do so.”, is responded by - “I do not think that this argument is sufficiently substantial to require refutation. Consolation would be more appropriate: perhaps this should be sought in the transmigration of souls. “</p>
  </li>
  <li>
    <p>“Those who believe in the two previous objections would probably not be interested in any criteria”. The two previous objections being referred to here are theological and “hands in the sand”.</p>
  </li>
  <li>
    <p>“The rules are thus quite time-invariant. This is quite true. The explanation of the paradox is that the rules which get changed in the learning process are of a rather less pretentious kind, claiming only an ephemeral validity. The reader may draw a parallel with the Constitution of the United States.”</p>
  </li>
</ul>]]></content><author><name></name></author><category term="papers-i-read" /><summary type="html"><![CDATA[Link to Paper]]></summary></entry><entry><title type="html">Understanding Deep Learning requires Rethinking Generalization</title><link href="http://localhost:4000/blog/2020/Understanding-Deep-Learning-requires-Rethinking-Generalization/" rel="alternate" type="text/html" title="Understanding Deep Learning requires Rethinking Generalization" /><published>2020-07-26T00:00:00+02:00</published><updated>2020-07-26T00:00:00+02:00</updated><id>http://localhost:4000/blog/2020/Understanding%20Deep%20Learning%20requires%20Rethinking%20Generalization</id><content type="html" xml:base="http://localhost:4000/blog/2020/Understanding-Deep-Learning-requires-Rethinking-Generalization/"><![CDATA[<p><a href="https://arxiv.org/abs/1611.03530">Link to Paper</a></p>

<p>The paper questions why some models generalize better than others. Which basically at heart means why neural networks work the way they do? Through experimentation, it is shown that traditional statistical approaches fail to explain generalization in neural networks and conclude that a precise formal measure to explain this is yet to exist. The authors discuss model capacity and find that even though regularisation improves generalization performance, it is still possible to get good generalization with no regularization.</p>

<p>The paper soundly questioned many notions that aren’t talked about much and are significant enough actually to be. Following are my major takeaways and best bits from the paper -</p>

<ul>
  <li>
    <p>I think it was intriguing that the hyperparameters did not have to be changed for the NN to fit random labels, inferring that hyperparameters might depend more on the network architecture than the data itself.</p>
  </li>
  <li>
    <p>The subplot of the learning curves on CIFAR-10 is what grabbed my attention the most. The NN achieves zero training error on all permutation of settings with varying converging speeds. The data with the correct labels and the shuffled pixels converges fast, which is obvious. Interestingly, random labels converged the slowest, which I thought would happen to the gaussian distributed data.</p>
  </li>
  <li>
    <p>Through the experiments, it can be gathered that explicit regularisation can be seen more like a tuning parameter for generalization as it’s absence does not imply bad generalization error. Another fascinating takeaway is that a certain amount of regularisation is picked up just by grturadient descent.</p>
  </li>
</ul>

<p>The authors argue that models likely do make use of massive memorization to perform well. As they have the capacity to fit noise, it is still unclear to me as to why generalized results are produced on real data. Maybe, we do need to rethink generalization.</p>

<p>Concluding, neural networks still seem mysterious. It looks like model architectures have been built such that they work well on images rather than the natural(actual) meaning of those images.</p>]]></content><author><name></name></author><category term="papers-i-read" /><category term="deep-learning" /><category term="generalization" /><summary type="html"><![CDATA[Link to Paper]]></summary></entry></feed>